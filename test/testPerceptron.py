#!/usr/bin/env python3
# coding=utf-8
# import
from unittest import TestCase
from random import randint, choice
from string import ascii_letters
from neuralnetworkcommon.perceptron import Perceptron, Layer, Sigmoid
# test perceptron
class testPerceptron(TestCase):
    # test sigmoid computing
    def testSigmoidValue(self):
        variables = [-4.759797336992447, 5.224268412298162, -0.8238109165048839, -4.335650860536461, -12.139774266734126, -3.9137186632355467, 2.3090778436678105, -2.6633803360485158, 4.912045083504539, -10.442216563757164]
        expectedValue = [0.008494569592952588, 0.9946445377970348, 0.30495530742883076, 0.012924129215778584, 5.342698960038116e-06, 0.019575273408768638, 0.9096260767034267, 0.0651690933628563, 0.9926963099778543, 2.9173618362790917e-05]
        actualValue = Sigmoid.value(variables)
        actualValue = [float(_) for _ in actualValue]
        self.assertListEqual(expectedValue, actualValue, "ERROR : sigmoïd value does not match")
        pass
    def testSigmoidDerivative(self):
        variables = [0.024861673929273992, 0.28109464441649784, 4.844212871290259e-07, 0.8458432780821669, 0.9974294986897912, 0.5396884426206188, 0.11165856728006232, 0.9982761962289739, 0.9706007225176077, 0.003034795109527507]
        expectedValue = [0.02424357109870845, 0.20208044529686048, 4.844210524650425e-07, 0.130392427005381, 0.0025638938332229657, 0.24842482752234984, 0.09919093163302611, 0.0017208322715850963, 0.02853495996590565, 0.003025585128170695]
        actualValue = Sigmoid.derivative(variables)
        actualValue = [float(_) for _ in actualValue]
        self.assertListEqual(expectedValue, actualValue, "ERROR : sigmoïd value does not match")
        pass
    # test layer computing
    def testDifferentialErrorOutput(self):
        expectedOutput = [0,0,1,0,0,0,0,0,0,0]
        actualOutput = [0.9995057415494378, 0.0005696693299897813, 6.773856462448391e-07, 0.7129941025529047, 0.008378539587771152, 0.0006705591635133233, 0.9652315201365399, 2.07564711785314e-05, 0.984934124954549, 0.0001956411273144735]
        expectedDifferentialError = [0.9995057415494378, 0.0005696693299897813, -0.9999993226143538, 0.7129941025529047, 0.008378539587771152, 0.0006705591635133233, 0.9652315201365399, 2.07564711785314e-05, 0.984934124954549, 0.0001956411273144735]
        actualDifferentialError = Layer.differentialErrorOutput(actualOutput,expectedOutput)
        actualDifferentialError = [float(_) for _ in actualDifferentialError]
        self.assertListEqual(expectedDifferentialError, actualDifferentialError, "ERROR : differential error output does not match")
        pass
    def testDifferentialErrorHidden(self):
        previousDifferentielError = [[0.14183407658948294],[0.14464286433485501],[0.12703726353950687],[0.08500328181266716],[0.09355259185226361],[0.10454788124775924],[0.07756524761984694],[0.033814213071683974],[-0.08176974843303718],[0.0825255766755945]]
        previousLayerWeights = [[-0.7339338396373078,-0.09171190968689302,0.9122745639261545,-0.8513173916984993,-0.8045567236137197,0.3760256831987825,-0.4882869188388077,-0.16430627283202415,-0.1477107907164379,0.6159008535197281,-0.7252812201318208,0.8132571694018083,0.12669455874542357,0.6472288737673857,0.26026542509041617],
            [-0.055150887866475706,-0.8670206367372424,0.0432210688836796,-0.7654661904221913,-0.9519694741261651,0.7522244736756616,0.6025507123354281,0.1853438832690888,-0.0461187754732737,-0.8627466418940204,-0.22009605272489363,0.513250107777429,-0.10882399748643556,0.8558924750865808,0.1640716588563096],
            [0.08807173146658442,0.7782244713793252,-0.9049346091312462,-0.23149227613708634,0.7149975656557102,-0.4999185332254117,0.21375858297494577,0.5866733028777451,0.8761531173193273,0.15397435305961582,-0.9457933332575676,0.39740420778464913,-0.9519379825765892,0.974233426263658,0.6275922245268184],
            [-0.35229939394358234,0.04799057478881452,0.5065128796329623,-0.60469030881464,0.3850504832667181,-0.06417838203463022,-0.8380561619707931,-0.2544993248214522,0.9477148323884432,-0.14902540028474576,0.8919620606403573,0.9223810830236232,-0.2449829632304652,0.9844058272694305,0.908219823522453],
            [-0.05893307437054185,0.5653770226752051,0.3499375315776432,-0.05067925307220578,0.4109552262513123,-0.5700091948879229,0.009649303756931182,-0.6143638270547374,-0.12709619535169003,0.5389043627792118,0.8636496840894341,-0.14288134339112202,0.2812826035570566,-0.5120400688698492,0.11462549144076317],
            [0.1768992855106295,-0.19185808872390253,-0.9236792411331485,-0.5704488327714192,0.49854122580540716,0.5788998407974435,0.9616383384984102,0.6033732403517966,0.6368617502438978,-0.28147250927263334,-0.5262111582015967,0.5360724428034356,-0.5506641586920458,0.591432065606339,0.6448246367795463],
            [-0.7109557836492975,0.5584818622758692,-0.6050828876131416,-0.03178242450170976,-0.383216859999747,-0.24615279149327574,0.5700969741818207,-0.1816139598841513,-0.47423686753531324,0.46998566986474066,-0.7952330413917452,0.5568353416661986,-0.5953101741319509,0.10253030827262233,0.8585439385437519],
            [0.9114487425713862,0.10385893412198066,-0.1538672765111444,0.7458496238727699,0.617931339253667,0.8020821338080604,0.38310696347715334,0.8337150723636286,0.4886782877599145,0.2414930614909696,0.4977770400313333,-0.7897929309964329,-0.5100598380863965,-0.05727040343051226,0.8080436203800161],
            [-0.020349060641251526,0.37483041922364313,-0.5086020357853125,-0.7469501680019115,0.16043699491118746,-0.4729718484291232,0.7074495870118833,0.1848059800017341,-0.8991298935502758,-0.9898446405799668,-0.4852331868857338,-0.3554407266661139,0.20005740942522876,0.027798910604015514,-0.5129507030526008],
            [0.07380317736892184,-0.7727682521787156,0.06536782070630753,0.9021452176115055,0.4744062246665979,-0.6868301984179919,-0.47873278251061335,-0.6365980946218983,0.9018052040566951,0.001548827777451356,0.11302299591561349,-0.11854790648478941,-0.3615901923193121,-0.9353053023398443,0.6587683945732208]]
        expectedDifferentialError = [-0.1344220721562209,-0.05023147223870325,-0.00524659161353101,-0.21837114866269153,-0.020477601224295115,0.09039302155467922,0.03507518596878928,0.008463924322890157,0.3466177496028463,0.11613457899661646,-0.14909963076277233,0.3969203348293972,-0.2804047519432634,0.3635263328280953,0.4859397506679662]
        actualDifferentialError = Layer.differentialErrorHidden(previousDifferentielError,previousLayerWeights)
        actualDifferentialError = [float(_) for _ in actualDifferentialError]
        self.assertListEqual(expectedDifferentialError, actualDifferentialError, "ERROR : differential error hidden does not match")
        pass
    def testComputeNewWeights(self):
        layer = Layer()
        layer.weights = [[-0.18142498326592915, 0.9127768930680651, 0.5851490152637835, 0.39951750591964763, -0.8716538097989281, 0.4555400718117186, -0.610623752160611, 0.768491278859532, 0.06183775388531654, -0.2864465501931208, -0.6391872952529665, -0.6779920943278348, 0.4891262144899948, -0.37370931627975423, -0.7773139411576371], [-0.11680081193569447, -0.3160450959531458, -0.9223320879555124, -0.16775837158120255, -0.6768736571610854, -0.1445971140289921, 0.01167888651935689, -0.7781563970805092, -0.22517500311351224, -0.6089663022517275, 0.376438052237841, -0.5435477877050503, 0.6720276277108008, -0.04301812061606625, 0.94173884592829], [0.1942698798535556, 0.6376162039655764, 0.71053292009958, 0.6400281855776488, 0.6469370900562907, -0.2363703394533443, 0.6757435436655064, 0.5933365607124284, 0.23095506337174987, 0.5430780824994483, 0.14453597705026744, -0.5781102335492665, -0.982664193083902, 0.3520637846792978, -0.7370802005471044], [-0.5775300538084585, -0.06310854848894332, 0.9678974937470828, 0.5487276350974375, -0.5780868491199977, -0.11634409521547551, -0.18429134387864443, -0.40170215693685685, 0.6408946728410845, -0.24896027654774144, -0.16132650149051053, -0.7931090154666871, 0.16630856749303424, -0.18441515961680666, 0.4343220720147791], [0.8312197934211241, -0.821437854356905, -0.355038182828183, 0.09381347813280771, -0.6043973699872462, 0.22421016163519836, -0.05482488615390335, 0.562569084963275, -0.6556513216666049, 0.5280116061098659, 0.8747902174640139, 0.9690163202397224, 0.7294842133764052, 0.5180547297923381, -0.1638302703203709], [-0.8608210052420062, 0.4919018940803861, -0.2652351554162353, 0.5384945740505664, -0.8579008569043578, 0.13593115872353634, 0.07749265390707838, -0.43079133053318186, 0.8229745851497567, 0.7560906371222582, -0.9029059192789832, 0.48519472007656805, 0.9766202363408276, 0.4752497895536021, 0.31945051160861904], [0.44128314318366657, 0.8346610341396541, 0.0597449852492713, 0.008960768114841144, 0.4820615242024071, -0.3847997925377238, -0.7881980710174932, -0.7284227575586024, 0.5211234177601454, -0.04037602778648708, 0.0744443725898003, 0.9415438246100247, 0.7259741986212171, -0.5717409162684384, -0.12159581440556533], [0.440349691898426, 0.7336986447526184, -0.041863763504363494, -0.4817000007754415, -0.26403905559892826, 0.8835060503992918, -0.441973274621158, 0.051184066574523124, 0.6241419194419939, -0.5082698430597317, -0.014751661331267929, -0.19840397149590827, 0.31484439375058937, -0.29821301267419154, -0.7845823717258789], [-0.8152060425706078, 0.5738854756129557, 0.7074371380518785, -0.8398184611819199, -0.7886414126013837, -0.846935562796663, -0.8135812806731575, -0.7255426127847422, -0.8241927366999717, -0.0002311314202241288, 0.38065791411421457, 0.9352890568542571, -0.147753202738222, -0.40734259915346205, -0.8098591352504529], [-0.24088715377343028, -0.5606111777606673, 0.5967429228847703, 0.8563145762329876, 0.21846139360838612, 0.9972664882533735, 0.4993637497231742, 0.35807274267266465, -0.8850009611116814, 0.7598389246618025, -0.05366822253515613, 0.5037304193545071, -0.5538095239081038, 0.01336084980267871, 0.39131839946764524]]
        input = (0.9462496492963102, 0.050016409581345726, 0.16211520684811256, 0.9879479779545183, 0.7582877511461974, 0.920878836285209, 0.2512672673372151, 0.09371770756475498, 0.6010634260699207, 0.1216037807230065, 0.9271263346043986, 0.1394034503218345, 0.08927296349194723, 0.367548752957228, 0.24046569912831703)
        output = [0.28399601541553166, 0.30501484366651005, 0.8298014162600169, 0.41732840297544566, 0.8021958754167957, 0.33372395002539135, 0.6356983021908221, 0.6176687459559471, 0.029949608721962142, 0.8263960019779597]
        # INFO : differentialErrorLayer!=output (index 7 : 0.6176687459559471!=-0.3823312540440529)
        differentialErrorLayer = [0.28399601541553166, 0.30501484366651005, 0.8298014162600169, 0.41732840297544566, 0.8021958754167957, 0.33372395002539135, 0.6356983021908221, -0.3823312540440529, 0.029949608721962142, 0.8263960019779597]
        expectedNewDifferentialErrorWeightsBiases = [[0.05774839690030647], [0.06465728715906499], [0.1171937052559847], [0.10147983098113503], [0.1272905586620176], [0.07420427957849257], [0.1472188084376666], [-0.09028908028746574], [0.0008701148906420094], [0.1185594394925827]]
        expectedOldWeights = [[-0.18142498326592915, 0.9127768930680651, 0.5851490152637835, 0.39951750591964763, -0.8716538097989281, 0.4555400718117186, -0.610623752160611, 0.768491278859532, 0.06183775388531654, -0.2864465501931208, -0.6391872952529665, -0.6779920943278348, 0.4891262144899948, -0.37370931627975423, -0.7773139411576371], [-0.11680081193569447, -0.3160450959531458, -0.9223320879555124, -0.16775837158120255, -0.6768736571610854, -0.1445971140289921, 0.01167888651935689, -0.7781563970805092, -0.22517500311351224, -0.6089663022517275, 0.376438052237841, -0.5435477877050503, 0.6720276277108008, -0.04301812061606625, 0.94173884592829], [0.1942698798535556, 0.6376162039655764, 0.71053292009958, 0.6400281855776488, 0.6469370900562907, -0.2363703394533443, 0.6757435436655064, 0.5933365607124284, 0.23095506337174987, 0.5430780824994483, 0.14453597705026744, -0.5781102335492665, -0.982664193083902, 0.3520637846792978, -0.7370802005471044], [-0.5775300538084585, -0.06310854848894332, 0.9678974937470828, 0.5487276350974375, -0.5780868491199977, -0.11634409521547551, -0.18429134387864443, -0.40170215693685685, 0.6408946728410845, -0.24896027654774144, -0.16132650149051053, -0.7931090154666871, 0.16630856749303424, -0.18441515961680666, 0.4343220720147791], [0.8312197934211241, -0.821437854356905, -0.355038182828183, 0.09381347813280771, -0.6043973699872462, 0.22421016163519836, -0.05482488615390335, 0.562569084963275, -0.6556513216666049, 0.5280116061098659, 0.8747902174640139, 0.9690163202397224, 0.7294842133764052, 0.5180547297923381, -0.1638302703203709], [-0.8608210052420062, 0.4919018940803861, -0.2652351554162353, 0.5384945740505664, -0.8579008569043578, 0.13593115872353634, 0.07749265390707838, -0.43079133053318186, 0.8229745851497567, 0.7560906371222582, -0.9029059192789832, 0.48519472007656805, 0.9766202363408276, 0.4752497895536021, 0.31945051160861904], [0.44128314318366657, 0.8346610341396541, 0.0597449852492713, 0.008960768114841144, 0.4820615242024071, -0.3847997925377238, -0.7881980710174932, -0.7284227575586024, 0.5211234177601454, -0.04037602778648708, 0.0744443725898003, 0.9415438246100247, 0.7259741986212171, -0.5717409162684384, -0.12159581440556533], [0.440349691898426, 0.7336986447526184, -0.041863763504363494, -0.4817000007754415, -0.26403905559892826, 0.8835060503992918, -0.441973274621158, 0.051184066574523124, 0.6241419194419939, -0.5082698430597317, -0.014751661331267929, -0.19840397149590827, 0.31484439375058937, -0.29821301267419154, -0.7845823717258789], [-0.8152060425706078, 0.5738854756129557, 0.7074371380518785, -0.8398184611819199, -0.7886414126013837, -0.846935562796663, -0.8135812806731575, -0.7255426127847422, -0.8241927366999717, -0.0002311314202241288, 0.38065791411421457, 0.9352890568542571, -0.147753202738222, -0.40734259915346205, -0.8098591352504529], [-0.24088715377343028, -0.5606111777606673, 0.5967429228847703, 0.8563145762329876, 0.21846139360838612, 0.9972664882533735, 0.4993637497231742, 0.35807274267266465, -0.8850009611116814, 0.7598389246618025, -0.05366822253515613, 0.5037304193545071, -0.5538095239081038, 0.01336084980267871, 0.39131839946764524]]
        expectedNewWeights = [[-0.20874718342309873, 0.9113327093320491, 0.5804680686094634, 0.37099129994576124, -0.8935487608078438, 0.4289504335442733, -0.6178788931017335, 0.7657852551730138, 0.04448252923984464, -0.2899577618900058, -0.665957325026697, -0.6820172572170635, 0.48654852922589503, -0.3843219919127476, -0.784257195474723], [-0.1473917795850525, -0.317662058631629, -0.9275730526965271, -0.199697389635614, -0.701388071598616, -0.17436787770719128, 0.0035557565904089563, -0.781186163445461, -0.24460656838361938, -0.6128975875366452, 0.346465315413217, -0.5480545121642619, 0.6691415538927811, -0.05490047324852211, 0.9339649160480676], [0.13882262860445027, 0.634685399784357, 0.7010334792151447, 0.5821375435093249, 0.6025038144527652, -0.2903309409113858, 0.6610200726311092, 0.5878449980136231, 0.19573463837425456, 0.5359524836814156, 0.09020929185392276, -0.5862788369836087, -0.9878953077693038, 0.33052658456866074, -0.7511707336810136], [-0.6255426810467324, -0.06564637688424241, 0.9596717818518736, 0.4985992381869482, -0.6165623055306882, -0.16306940954563917, -0.19704062378888057, -0.4064573854986622, 0.6103967653978257, -0.2551304421049603, -0.20836881335741733, -0.8001823347551105, 0.16177886486986032, -0.2030645522805199, 0.42212086276262806], [0.7709954701747913, -0.8246211627158438, -0.3653560504518354, 0.030935253111387076, -0.6526588057222285, 0.16560057086981192, -0.07081686157031968, 0.5566043952870543, -0.6939061713144782, 0.5202720995180433, 0.8157830029229826, 0.9601439487042829, 0.7238024106782533, 0.4946619867426114, -0.17913477691091895], [-0.8959288920057232, 0.4900461782603428, -0.27124997648267657, 0.5018395900679947, -0.8860349550478572, 0.10176458341072407, 0.06817010062987111, -0.4342684580199771, 0.8006738458935072, 0.7515788766509723, -0.9373042901477672, 0.4800225537756241, 0.9733080183699491, 0.4616129443420199, 0.31052871962504136], [0.3716302702566852, 0.8309793560292061, 0.047811781458368806, -0.063761493941592, 0.42624441461409657, -0.45258513503441056, -0.8066937048658799, -0.7353212621771988, 0.47687949706940774, -0.04932720963626523, 0.006199155463979825, 0.9312824196857847, 0.7194028689657253, -0.5987959609949951, -0.13929635125346596], [0.4830676971770764, 0.7359566125628089, -0.03454514704089932, -0.43709954362475406, -0.22980650377680784, 0.9250787019914833, -0.43062992938404704, 0.05541490938585882, 0.651276651409137, -0.5027800962992522, 0.02710303069959226, -0.19211066683667935, 0.3188745806347016, -0.281620193241535, -0.7737266583183897], [-0.8156177155256665, 0.5738637156015791, 0.7073666086241395, -0.8402482753053189, -0.7889713113332155, -0.8473361979906274, -0.813690596368578, -0.7255833853711766, -0.8244542338185936, -0.00028403605040685565, 0.38025456089959175, 0.9352284083452912, -0.14779204160565507, -0.4075025039749545, -0.809963751643203], [-0.29698056779374205, -0.5635761365033651, 0.5871327788562021, 0.7977492969759286, 0.17351030823339403, 0.9426770489180953, 0.48446869653400765, 0.3525171832329611, -0.920631832558852, 0.7526302866204532, -0.10862801181991122, 0.49546662188776275, -0.5591016001648274, -0.00842733726572464, 0.3770636602147226]]
        actualNewDifferentialErrorWeightsBiases, actualOldWeights = layer.computeNewWeights(input,output,differentialErrorLayer)
        actualNewDifferentialErrorWeightsBiases = [[float(__) for __ in _] for _ in actualNewDifferentialErrorWeightsBiases]
        actualOldWeights = [[float(__) for __ in _] for _ in actualOldWeights]
        layer.weights = [[float(__) for __ in _] for _ in layer.weights]
        self.assertListEqual(expectedNewDifferentialErrorWeightsBiases, actualNewDifferentialErrorWeightsBiases, "ERROR : NewDifferentialErrorWeightsBiases does not match")
        self.assertListEqual(expectedOldWeights, actualOldWeights, "ERROR : OldWeights does not match")
        self.assertListEqual(expectedNewWeights, layer.weights, "ERROR : NewWeights does not match")
        pass
    def testComputeNewBiases(self):
        layer = Layer()
        layer.biases = [-0.07391145943253177, -0.0037468009325435595, 0.03565692328593865, -0.02759268588830517, -0.039614807898258324, -0.005223318002614438, -0.01933930374100669, -0.021853469283982845, -0.05793415966528307, -0.010348911482826363]
        differentialErrorWeightsBiases = [0.12221130088752075, 0.0021799759561826064, 0.13015892574790985, 0.014663059022990092, -0.13426455800036569, 0.006722431369416266, 0.010333221101926979, 0.03565200697170734, 0.12498946577738178, 0.0769010884629075]
        expectedBiases = [-0.13501710987629215, -0.0048367889106348625, -0.02942253958801628, -0.034924215399800215, 0.02751747110192452, -0.008584533687322572, -0.024505914291970177, -0.039679472769836514, -0.12042889255397396, -0.04879945571428011]
        layer.computeNewBiases(differentialErrorWeightsBiases)
        layer.biases = [float(_) for _ in layer.biases]
        self.assertListEqual(expectedBiases, layer.biases, "ERROR : biases does not match")
        pass
    def testPassBackwardOutput(self):
        layer = Layer()
        layer.weights = [[-0.10257072717776294, 0.0747994328425663, 0.4444664837950769, -0.6138391981655815, -0.6009161676169879, -0.8632071569577293, 0.9036314566569899, -0.30929259871489023, -0.075749460700548, 0.15843606278486222, -0.9129099866106964, -0.5208929129470972, 0.2867298108991634, 0.08529862937392707, -0.4935038628906705], [-0.9291106004652299, 0.9824984824584955, -0.504707093988251, -0.1500504510802554, 0.43549641582555787, -0.43880646969014503, -0.16759280495996487, -0.5588827786531232, -0.07586089397967477, 0.9899891369867164, -0.6597706860569381, 0.5133291432758966, -0.8865080591946441, -0.275421265852702, 0.49015247837265474], [-0.026894285920792127, -0.4858324335504356, 0.18145707803996247, 0.29428828331444623, -0.354212951121438, -0.3210772593512343, -0.5394479185443906, 0.803118695642004, 0.6190615042113297, 0.6515185262595797, -0.7425952549499715, 0.8659568011912839, -0.5131518053456605, 0.2610082346271567, -0.09601743021375353], [-0.17561306539969257, -0.7386940407021305, 0.8152867176721212, -0.8705554975442003, -0.6204702207089228, 0.3342997397730578, -0.5064999800462002, 0.34815315046049444, 0.14760899749049927, 0.157178613769706, -0.9993853062271618, -0.6569272282078005, 0.1804599375415481, -0.7030112806874445, -0.7350420668576956], [0.8828741950466388, -0.6296617789429941, -0.707404725224118, 0.7335250638861168, 0.5381069337865159, -0.1437882491685758, -0.5173879178220417, 0.7688410309912292, 0.15616424372198456, -0.9989704223747622, -0.0620925838809574, -0.4828480734363554, -0.7748116556817006, -0.012959360928265218, 0.029074331827384947], [-0.1026391403115614, 0.5720859155891993, -0.21429822750298455, 0.12591994053889377, 0.659135276324764, -0.844438985407066, 0.2590272199428978, -0.4439967565313696, -0.6346081637257106, 0.5333793202900743, 0.26010394134859927, -0.06481444939683234, -0.9217189919871613, 0.6268996954230708, -0.24932145829117358], [0.23458265829162528, -0.390616401325105, -0.09682066999866024, -0.44149596196458907, 0.1529272519776923, -0.491005866840424, -0.91426658905155, -0.6911201146849426, 0.22265846077555485, 0.5258991423127748, -0.4865153141787022, 0.588225652042933, -0.7055011879028201, 0.5609807271893301, 0.4673620113856318], [-0.08273164746601647, 0.5686179258387005, -0.633284095647473, 0.89690747959844, 0.11696837247988556, 0.967565543147695, 0.41836394328548576, 0.42421518380125844, 0.15291399712338394, 0.9215786938091002, 0.6525027713430687, -0.052089982836532656, -0.200173593795143, 0.8422955089117492, 0.7519901898942041], [-0.30914007492382867, 0.777624918700575, 0.8562810593245835, 0.11430546897163096, 0.815770403621451, -0.4763968998414343, -0.8385955806986769, 0.8960490362738174, -0.11299053732624875, 0.5173205475212033, 0.6983817829002903, 0.3801521711039224, 0.07889986545416261, -0.283358771677525, -0.3209550950829625], [0.44709855896243633, 0.37345083182098016, -0.18913324731545345, -0.2172585303914083, -0.7592507954495509, -0.43318310201377197, 0.19511321354229638, 0.408987664303919, 0.5678047264144366, -0.35051036170723937, 0.8263969649181553, 0.7710547106793784, 0.6336909845853937, -0.6822396326805611, 0.13003257719586214]]
        layer.biases = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        actualInput = (0.31942452603548016, 0.8634857077605765, 0.48741507665785133, 0.4757247326701572, 0.4651309154302325, 0.6731706614705184, 0.9503679395504243, 0.1551975950107844, 0.9419948856546926, 0.28525794125883863, 0.4347520000650441, 0.7214222589192145, 0.5337525483295144, 0.7533593020711252, 0.5804654657373496)
        actualOutput = [0.2766067792036662, 0.448594490952139, 0.4923254553334992, 0.05808073635912464, 0.19844189707731058, 0.4472751664233962, 0.2962578357691128, 0.966721444131264, 0.669658812997892, 0.7547386574291586]
        expectedOutput = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
        expectedNewDifferentialErrorWeightsBiases = [[0.05534776318629609], [0.11096319997053222], [0.12305236653566727], [0.003177444009961003], [0.0315647060381167], [0.11057540775865726], [0.061766538587614064], [0.03110048605269988], [0.1481391684199751], [-0.04539988967790227]]
        expectedOldWeights = [[-0.10257072717776294, 0.0747994328425663, 0.4444664837950769, -0.6138391981655815, -0.6009161676169879, -0.8632071569577293, 0.9036314566569899, -0.30929259871489023, -0.075749460700548, 0.15843606278486222, -0.9129099866106964, -0.5208929129470972, 0.2867298108991634, 0.08529862937392707, -0.4935038628906705], [-0.9291106004652299, 0.9824984824584955, -0.504707093988251, -0.1500504510802554, 0.43549641582555787, -0.43880646969014503, -0.16759280495996487, -0.5588827786531232, -0.07586089397967477, 0.9899891369867164, -0.6597706860569381, 0.5133291432758966, -0.8865080591946441, -0.275421265852702, 0.49015247837265474], [-0.026894285920792127, -0.4858324335504356, 0.18145707803996247, 0.29428828331444623, -0.354212951121438, -0.3210772593512343, -0.5394479185443906, 0.803118695642004, 0.6190615042113297, 0.6515185262595797, -0.7425952549499715, 0.8659568011912839, -0.5131518053456605, 0.2610082346271567, -0.09601743021375353], [-0.17561306539969257, -0.7386940407021305, 0.8152867176721212, -0.8705554975442003, -0.6204702207089228, 0.3342997397730578, -0.5064999800462002, 0.34815315046049444, 0.14760899749049927, 0.157178613769706, -0.9993853062271618, -0.6569272282078005, 0.1804599375415481, -0.7030112806874445, -0.7350420668576956], [0.8828741950466388, -0.6296617789429941, -0.707404725224118, 0.7335250638861168, 0.5381069337865159, -0.1437882491685758, -0.5173879178220417, 0.7688410309912292, 0.15616424372198456, -0.9989704223747622, -0.0620925838809574, -0.4828480734363554, -0.7748116556817006, -0.012959360928265218, 0.029074331827384947], [-0.1026391403115614, 0.5720859155891993, -0.21429822750298455, 0.12591994053889377, 0.659135276324764, -0.844438985407066, 0.2590272199428978, -0.4439967565313696, -0.6346081637257106, 0.5333793202900743, 0.26010394134859927, -0.06481444939683234, -0.9217189919871613, 0.6268996954230708, -0.24932145829117358], [0.23458265829162528, -0.390616401325105, -0.09682066999866024, -0.44149596196458907, 0.1529272519776923, -0.491005866840424, -0.91426658905155, -0.6911201146849426, 0.22265846077555485, 0.5258991423127748, -0.4865153141787022, 0.588225652042933, -0.7055011879028201, 0.5609807271893301, 0.4673620113856318], [-0.08273164746601647, 0.5686179258387005, -0.633284095647473, 0.89690747959844, 0.11696837247988556, 0.967565543147695, 0.41836394328548576, 0.42421518380125844, 0.15291399712338394, 0.9215786938091002, 0.6525027713430687, -0.052089982836532656, -0.200173593795143, 0.8422955089117492, 0.7519901898942041], [-0.30914007492382867, 0.777624918700575, 0.8562810593245835, 0.11430546897163096, 0.815770403621451, -0.4763968998414343, -0.8385955806986769, 0.8960490362738174, -0.11299053732624875, 0.5173205475212033, 0.6983817829002903, 0.3801521711039224, 0.07889986545416261, -0.283358771677525, -0.3209550950829625], [0.44709855896243633, 0.37345083182098016, -0.18913324731545345, -0.2172585303914083, -0.7592507954495509, -0.43318310201377197, 0.19511321354229638, 0.408987664303919, 0.5678047264144366, -0.35051036170723937, 0.8263969649181553, 0.7710547106793784, 0.6336909845853937, -0.6822396326805611, 0.13003257719586214]]
        actualNewDifferentialErrorWeightsBiases, actualOldWeights = layer.passBackward(actualInput,actualOutput,expectedOutput)
        actualNewDifferentialErrorWeightsBiases = [[float(__) for __ in _] for _ in actualNewDifferentialErrorWeightsBiases]
        actualOldWeights = [[float(__) for __ in _] for _ in actualOldWeights]
        self.assertListEqual(expectedNewDifferentialErrorWeightsBiases, actualNewDifferentialErrorWeightsBiases, "ERROR : pass backward output actualNewDifferentialErrorWeightsBiases does not match")
        self.assertListEqual(expectedOldWeights, actualOldWeights, "ERROR : pass backward output actualOldWeights does not match")
    def testPassBackwardHidden(self):
        layer = Layer()
        layer.weights = [[0.26691597724361515, -0.16230916379667626, -0.43469474226857674, -0.1343332117128999, -0.28596799930197037, -0.03464110223163197, -0.49153931496486436, 0.947688475524489, -0.5449746782652622, -0.030574668136766237, 0.023684422303667407, 0.0500619025263056, -0.07252808845059722, 0.6565445645500203, -0.3335548460628166, -0.24793026656661055, -0.5394359015234784, -0.9621681723960525, 0.4844644814913335, 0.38610333358685156, 0.6971356504048709, 0.31562409418012694, 0.5561933738859304, 0.08654098841587121, 0.6957873362868974, -0.12767009043444832, 0.07874622790148678, 0.8589715280119565, 0.24869715946421178, 0.37005075668414356], [0.606500353892176, 0.5225264467647572, 0.8539289359298596, -0.48625400269822516, 0.27994942157201863, 0.31280062993694857, -0.2039618233937155, 0.16611845558112104, -0.03160149932526357, 0.2021373058331455, 0.24326943851437433, 0.8502469015584906, 0.16532091373273516, -0.08876040449239064, 0.20393823210169426, 0.9191664446450503, -0.06192871699231084, 0.6601445752403001, 0.5455991385495698, -0.34959298594427635, 0.9381535058706854, -0.48287429499765877, -0.4117529484270612, 0.3970078937503849, 0.9077898573533525, -0.784761668725728, 0.1881555393727503, -0.8468162875009921, 0.4558942154655381, -0.5964960548813616], [-0.7908752540730457, 0.7362107881649131, -0.03857097268291665, 0.7680161983655023, 0.5645166463688704, 0.20442175455126455, 0.7335872843696607, -0.4913773140883131, 0.2992777942257765, -0.09181198370559174, -0.04951115480551538, -0.6894339856699607, 0.3332385353539189, 0.6948516160880953, 0.608758977554523, 0.4376525636144539, 0.7585665406352771, 0.29048383784502785, -0.5286436402629795, -0.4903382149830793, 0.37907642224690563, -0.2531485836062015, 0.6273352696497367, -0.20529203094863635, -0.05525515698014538, -0.10889579295690632, 0.6968408318122528, 0.44967974510835784, -0.8579149484763613, -0.9114658140089473], [-0.623703042607958, -0.7708323578735885, 0.7530955365318404, -0.22452396096471805, -0.2895337642055118, 0.2097086845754912, 0.8532897652283604, 0.8115924861083739, 0.7107291290635123, -0.04744898238020223, -0.3760638826467775, -0.9091802024928379, 0.7419168614666389, 0.7361296016469181, -0.04131661903755268, 0.8217334050821006, -0.3040574533895646, -0.285429850995909, 0.8015422796248615, -0.8809229018702838, -0.7025222937603173, -0.611759024155283, -0.30894653682550066, 0.09140312535729711, 0.619429796558755, -0.5320280106210091, 0.36963835673429846, 0.01791680094238579, -0.12205612736861338, -0.8522852297674706], [0.33375710982556583, 0.3296425387185524, -0.7171669529930449, -0.6214224570442153, -0.5453844795359788, 0.2764174242105011, -0.07684068151595724, -0.9584950622826214, 0.1738470972457682, 0.943320358170975, 0.8794049133249924, 0.13642511231436183, 0.08375535315005544, 0.9429587550560647, 0.572091076071086, -0.6724720034616365, -0.5025541393908317, -0.7096610255418787, -0.9555426894011361, -0.522456443194544, 0.6946146049241477, -0.8385185061585572, -0.8795052469136928, -0.9070082528482522, -0.32231023117802704, 0.9117908903694005, -0.8734911802557694, -0.09919692907584632, -0.5326579538330758, -0.1670948119429183], [0.7776007063632282, -0.6838107346243338, 0.9419546331067175, -0.8449619345986916, 0.8123094710054084, 0.9785726656424001, 0.7901431948224353, -0.39942685775243514, 0.1388170815585732, -0.2529380991199046, 0.6465306158260573, -0.6320130069129253, 0.6702404934723161, -0.5456638139752135, -0.04209248645225472, -0.7976653931567277, 0.9489627243783254, -0.7703574452986615, -0.23271397007188788, -0.3326417179970991, 0.9934879303636219, -0.07115257954925913, -0.929992028520084, -0.4781561586860472, -0.4689847826735911, 0.8856060859064188, -0.8515101045397426, 0.6464910218945379, -0.41365736858531443, -0.541260368128418], [0.8730257944912467, 0.8555099083380586, 0.39166220792072637, 0.0772561949433439, 0.3845853950359408, -0.23147274265406348, -0.0829992942527027, 0.4911377534741639, 0.8937118382617057, -0.4608446658151317, -0.025233404172197105, 0.6140679753263885, 0.26850620666564073, -0.28359301972397555, 0.6796390846953244, 0.48629194432512635, 0.2968714712391931, -0.07911329774651188, 0.991916986740037, 0.2813827476951407, -0.04853407905200813, -0.6005046367686679, -0.14304013354765055, 0.34286787732081714, -0.37445535142004815, -0.4400279267600409, -0.33907321248114686, -0.37837303194360317, 0.945141709094852, -0.683971963246832], [0.8540940740758476, 0.04861388945661349, -0.9467378842956955, 0.8365728984594432, -0.671038048562083, 0.25851231966164834, 0.9622742773321897, -0.1624026626986581, -0.9896560629018187, 0.8072858865671102, 0.9736878988942121, 0.17861290153450882, 0.10940544690711618, -0.8730713613228547, -0.6646436186777103, 0.23679883953292813, -0.4552336039826439, 0.6408472340913358, -0.6543284426483371, -0.30141157985381684, 0.44496382416060487, 0.17500744902661003, -0.32023394897066493, -0.0022167235368273364, -0.381770834023895, -0.28775636020658224, 0.3675656809092278, -0.34447310875318604, 0.07300873631407545, -0.37317126347410223], [0.5391780685040928, 0.02367004219503155, 0.13863564506197767, -0.04530548981712346, 0.5656804593949312, 0.44250184454097274, -0.36151010137978945, -0.6628246482899305, -0.1172038013204948, 0.7237079073843, -0.8376957486882841, 0.871765853256397, -0.28838296148084797, 0.27741791906661595, 0.5583524261505393, 0.18503979073451826, 0.757222149588137, -0.9262281598706767, -0.6096037363306197, -0.18917605827101602, -0.1658557691342144, -0.10215967708145857, -0.7025320926885859, -0.024967166137099595, 0.8703418196443338, -0.6960851941539934, -0.633930594488638, -0.686724307188529, -0.7910965683428357, -0.8887087210359776], [0.9826252270056228, 0.40973357525194265, 0.5565266781591525, 0.6927467781725694, -0.8644455733310281, -0.8626144758512653, 0.6452054904688331, 0.9377428552800928, -0.8268352150728222, 0.7652172017434902, 0.5795276366570672, 0.5060762913001795, 0.37824547793244845, -0.3560154763982779, 0.05533563067178626, 0.12264136690894478, 0.8512661591913149, -0.641903435163274, 0.5585270479669164, -0.7403182557023502, -0.2582571909751761, 0.35748713180284786, -0.18857210682082926, 0.7721276445180794, -0.05374254228525355, -0.8501368202276283, -0.49378756966072723, 0.4493239143938239, 0.7153738694310456, -0.21130702628943188], [0.5681618850318559, 0.11799381548531862, 0.2685162487814896, 0.7307796328312903, -0.864167663296346, 0.6579880053501204, 0.7767455537777987, 0.9177711486338844, 0.08683469970661939, 0.03139375295865032, 0.25041538750477943, -0.9359558980973712, 0.8888963622593944, 0.28906388709363173, -0.7908913007127956, -0.3865314011912966, -0.5175825060912029, 0.8157868742279841, 0.31443947376953685, -0.7308420329280938, 0.2604846470384399, 0.10741707309008408, 0.7078309292452174, 0.5580511509992456, -0.8108251643585942, 0.8925156100829921, 0.17481034448447796, -0.5700146305402753, -0.568805108683963, -0.9078771571749267], [0.6081747675829952, -0.7700607316764247, 0.39734904277630223, 0.8270959443978456, -0.40337570923748456, 0.18757187183462687, 0.5266801888683978, 0.9084090625572838, 0.1205113065098058, -0.49455829859582434, 0.26242478410855097, -0.9219005436971155, -0.9551255115045725, 0.495899005247477, 0.5609575168335097, -0.6630106285450961, 0.5896689750752395, 0.659971371452942, 0.20055286772248015, 0.26817567517585683, 0.8607677309697734, 0.5864095513290775, 0.39982592268179395, -0.8901015808217161, 0.4638905416434107, -0.2781527894057818, 0.7074674894562092, -0.5907627538687354, -0.3602813471960278, 0.22602081495466209], [-0.6592014750337383, 0.14984012978198957, -0.1554145963807878, 0.8639803161217601, 0.9735709650845186, -0.8424151206981372, 0.3111870126407652, 0.960161521752031, -0.6462387108255427, -0.7121819853071758, -0.37717077910961283, 0.4803263686170032, -0.16703526360721654, -0.46350620057514713, 0.0009271914037238815, -0.5233656201445529, 0.3372666567211897, -0.9994372244106846, 0.8529405895737419, 0.31384540519055726, 0.31050363357476596, -0.8424808509876989, 0.9421457003902372, 0.8098707330552466, -0.10746487787330938, -0.9180363148669084, 0.4313386059045914, -0.18757785134219707, -0.26593384174646095, -0.35384538265872245], [0.3824054980394753, -0.5304276002750439, -0.47410931986790983, -0.7086129479942089, 0.9883940326431866, -0.5231574029585295, -0.42743357580303853, 0.29242391912769383, 0.5570403816946901, 0.3399272990989215, -0.3720050721675219, 0.04547160034793474, -0.7495636610751786, 0.6267846571014775, 0.8932647046045683, 0.7524585183008636, 0.6378543885435521, -0.9822537078353901, 0.12216386639545074, -0.8265555822818544, -0.5279783265028846, -0.10576510302025266, -0.9642396781375027, -0.679187088516094, 0.47507173093856214, -0.7761749453657296, 0.6634812246739148, 0.8625978325906483, 0.6759897643362995, 0.6155072891021787], [0.9845754882777917, 0.036695459737910996, -0.17453971350983322, -0.4715856513583987, 0.16472829853294324, 0.12835025628512287, 0.34011427648304116, 0.6894300295534845, 0.20749024079465372, 0.3385576593132551, -0.4954544848754281, -0.20308048893486208, 0.38721011018193185, -0.27304930156410445, 0.830900268203846, 0.4861611154365386, 0.9737832836455587, -0.979383455749931, -0.765953129349398, -0.8860482583664704, -0.14449188300301463, 0.020705145708449946, 0.5210278914524638, 0.40005367370092326, -0.2819784631107438, -0.49664184468628725, -0.03231743704030676, 0.7405601223141527, -0.8871420203585085, -0.37217576227560456]]
        layer.biases = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        actualInput = (0.0020652999070587736, 0.9201901232288947, 0.5095353045845822, 0.9992521581947311, 0.9999833215539565, 0.9994291254652697, 0.9936738039632953, 0.9998107200650851, 0.9514231642530041, 0.8232079689299381, 0.7568666602628913, 0.04080163121399534, 0.99376441465699, 0.7754375195377347, 0.9997908319082374, 0.9671634578245646, 0.0008952279083242362, 0.0007773655495024629, 0.9882039153448073, 0.008958072517513939, 0.9999482490453361, 0.9982477086099972, 0.003508423901757373, 0.941216189863121, 0.9458615982916744, 0.9999765492544014, 0.00031987098064781023, 0.1681767259687143, 0.011589692551085886, 0.9924015051594391)
        actualOutput = [0.8314071364073562, 0.962327445978593, 0.9471084144956656, 0.897559565111361, 0.23716913373451642, 0.7765690415926663, 0.9192826734603475, 0.2964436427314558, 0.23293479415377477, 0.8934620566327159, 0.9518645948215896, 0.8645697931096519, 0.37725525050629827, 0.5155865764492682, 0.6972184014544008]
        differentialErrorWeightsBiasInput = [[0.1417558230195636], [0.13637783372812592], [0.14811816086110452], [0.08706364868496268], [0.013371317162058702], [0.12270500774122234], [0.14786242569528263], [-0.04682061459348302], [0.10834626002237732], [0.08850276620744514]]
        previousLayerWeights = [[0.1318100692686479, -0.3797382897798587, -0.30013377849480594, 0.6820159068509102, 0.3841685966761246, -0.5580650286667095, 0.9128813798661148, 0.9093370558632237, -0.0888718086126099, -0.6062071336864772, -0.14882922314286162, 0.12317052745154866, 0.9945176096063313, 0.6164484585807053, -0.858185126184527], [-0.954047784097442, 0.19035643134624447, 0.8763264081077431, -0.4056755771989633, -0.6965691881486653, -0.04690240732480189, 0.28628165219382096, -0.5931840850423156, -0.6248161203931912, -0.41589077807106967, 0.804618576710233, -0.07766665817695229, -0.26359182781971113, 0.8155085901762056, -0.05475829645761321], [-0.9525139083192309, -0.2970975521778154, 0.37211386873594, 0.3430267788543542, 0.014201020593651137, -0.9148352557835397, 0.1733204484903892, 0.978044344794387, -0.15740958845940511, -0.3228016341099591, 0.78553390933588, 0.1863277647947581, -0.11470190769033106, 0.5753922709762831, 0.7267713505427891], [-0.9700190481353586, 0.17757531886176148, -0.7309231726498313, 0.7912065649726898, 0.214633591467704, 0.42266549535351694, -0.9419133026546764, 0.11200844595760495, -0.3287365751623126, -0.29364401369826765, 0.2385662518045779, 0.04747014714484288, 0.3636143064218642, 0.2679366810606978, 0.49504889492227955], [0.5351503046449024, 0.6896946804136443, 0.21012343639348408, 0.9131844405214857, 0.8977809314584146, 0.8109799441464596, 0.22831230619784182, 0.5274011418012139, -0.4738601336377355, 0.36957281490396676, 0.743463789405693, 0.17064476571818932, 0.9440862287180103, 0.22214554123403496, -0.8732335343388027], [0.04928656668978504, -0.20604404515709618, 0.6393871634890376, 0.633878423086744, -0.9418092624175343, -0.1370433728003868, 0.43907438830813894, -0.23196987379249423, 0.5371668406891994, 0.38341826690992886, -0.7155542744709056, 0.8417361927194587, 0.659519608269125, 0.5478260549426721, -0.8344687163942754], [-0.09127016298059187, 0.9443642499003979, -0.5036402104554061, -0.2539658315532076, -0.3393740979633393, -0.9060073212082707, 0.32177304007835605, 0.6325292158993501, 0.7324860537908842, 0.6324090019153135, 0.7889025190930987, -0.6430893926972305, 0.4892717591953475, -0.31052533848996533, -0.018189550012757794], [0.7219762801084058, 0.23356483391722738, 0.09194351262079059, -0.6143071794010855, -0.7147932074307872, -0.5053267780943809, -0.9229500482496509, 0.160752632854807, -0.5530061533691473, 0.7706011767799552, 0.8473626723279994, 0.4584780227108811, 0.670593046850517, 0.03397263864129685, 0.0981206906152241], [-0.39333792274260126, -0.19371613240683971, 0.9319532884879311, 0.5595462230357009, 0.24948677620487292, -0.4001630179655695, 0.8581232307635145, -0.3315586129451167, -0.4535483544842549, -0.9662509790771772, -0.9962975909971357, 0.6202913566747275, 0.6372102086121361, -0.8151984517279856, 0.012029745067721587], [0.8554187369082478, -0.5337314427357667, -0.2967126929575561, 0.23721156910169539, 0.9739061804009788, 0.6195127839961094, 0.8259805520293424, 0.7521095342493678, 0.09710492513325186, -0.7038694135644943, 0.6871478042006689, -0.4584768056393993, 0.8651593647457174, -0.38232777032060583, 0.6637880399834901]]
        expectedNewDifferentialErrorWeightsBiases = [[-0.047372927395923144], [-0.0004350473021621072], [0.007296243155056548], [0.02977847463389112], [-0.004848241394838925], [-0.05014680987642057], [0.031603458984740304], [0.062121913694972664], [0.0006226108280286196], [-0.02604292298006819], [0.00814377748721566], [0.006351060853580193], [0.0939275464611393], [0.05186979670069245], [-0.00837552305053697]]
        expectedOldWeights = [[0.26691597724361515, -0.16230916379667626, -0.43469474226857674, -0.1343332117128999, -0.28596799930197037, -0.03464110223163197, -0.49153931496486436, 0.947688475524489, -0.5449746782652622, -0.030574668136766237, 0.023684422303667407, 0.0500619025263056, -0.07252808845059722, 0.6565445645500203, -0.3335548460628166, -0.24793026656661055, -0.5394359015234784, -0.9621681723960525, 0.4844644814913335, 0.38610333358685156, 0.6971356504048709, 0.31562409418012694, 0.5561933738859304, 0.08654098841587121, 0.6957873362868974, -0.12767009043444832, 0.07874622790148678, 0.8589715280119565, 0.24869715946421178, 0.37005075668414356], [0.606500353892176, 0.5225264467647572, 0.8539289359298596, -0.48625400269822516, 0.27994942157201863, 0.31280062993694857, -0.2039618233937155, 0.16611845558112104, -0.03160149932526357, 0.2021373058331455, 0.24326943851437433, 0.8502469015584906, 0.16532091373273516, -0.08876040449239064, 0.20393823210169426, 0.9191664446450503, -0.06192871699231084, 0.6601445752403001, 0.5455991385495698, -0.34959298594427635, 0.9381535058706854, -0.48287429499765877, -0.4117529484270612, 0.3970078937503849, 0.9077898573533525, -0.784761668725728, 0.1881555393727503, -0.8468162875009921, 0.4558942154655381, -0.5964960548813616], [-0.7908752540730457, 0.7362107881649131, -0.03857097268291665, 0.7680161983655023, 0.5645166463688704, 0.20442175455126455, 0.7335872843696607, -0.4913773140883131, 0.2992777942257765, -0.09181198370559174, -0.04951115480551538, -0.6894339856699607, 0.3332385353539189, 0.6948516160880953, 0.608758977554523, 0.4376525636144539, 0.7585665406352771, 0.29048383784502785, -0.5286436402629795, -0.4903382149830793, 0.37907642224690563, -0.2531485836062015, 0.6273352696497367, -0.20529203094863635, -0.05525515698014538, -0.10889579295690632, 0.6968408318122528, 0.44967974510835784, -0.8579149484763613, -0.9114658140089473], [-0.623703042607958, -0.7708323578735885, 0.7530955365318404, -0.22452396096471805, -0.2895337642055118, 0.2097086845754912, 0.8532897652283604, 0.8115924861083739, 0.7107291290635123, -0.04744898238020223, -0.3760638826467775, -0.9091802024928379, 0.7419168614666389, 0.7361296016469181, -0.04131661903755268, 0.8217334050821006, -0.3040574533895646, -0.285429850995909, 0.8015422796248615, -0.8809229018702838, -0.7025222937603173, -0.611759024155283, -0.30894653682550066, 0.09140312535729711, 0.619429796558755, -0.5320280106210091, 0.36963835673429846, 0.01791680094238579, -0.12205612736861338, -0.8522852297674706], [0.33375710982556583, 0.3296425387185524, -0.7171669529930449, -0.6214224570442153, -0.5453844795359788, 0.2764174242105011, -0.07684068151595724, -0.9584950622826214, 0.1738470972457682, 0.943320358170975, 0.8794049133249924, 0.13642511231436183, 0.08375535315005544, 0.9429587550560647, 0.572091076071086, -0.6724720034616365, -0.5025541393908317, -0.7096610255418787, -0.9555426894011361, -0.522456443194544, 0.6946146049241477, -0.8385185061585572, -0.8795052469136928, -0.9070082528482522, -0.32231023117802704, 0.9117908903694005, -0.8734911802557694, -0.09919692907584632, -0.5326579538330758, -0.1670948119429183], [0.7776007063632282, -0.6838107346243338, 0.9419546331067175, -0.8449619345986916, 0.8123094710054084, 0.9785726656424001, 0.7901431948224353, -0.39942685775243514, 0.1388170815585732, -0.2529380991199046, 0.6465306158260573, -0.6320130069129253, 0.6702404934723161, -0.5456638139752135, -0.04209248645225472, -0.7976653931567277, 0.9489627243783254, -0.7703574452986615, -0.23271397007188788, -0.3326417179970991, 0.9934879303636219, -0.07115257954925913, -0.929992028520084, -0.4781561586860472, -0.4689847826735911, 0.8856060859064188, -0.8515101045397426, 0.6464910218945379, -0.41365736858531443, -0.541260368128418], [0.8730257944912467, 0.8555099083380586, 0.39166220792072637, 0.0772561949433439, 0.3845853950359408, -0.23147274265406348, -0.0829992942527027, 0.4911377534741639, 0.8937118382617057, -0.4608446658151317, -0.025233404172197105, 0.6140679753263885, 0.26850620666564073, -0.28359301972397555, 0.6796390846953244, 0.48629194432512635, 0.2968714712391931, -0.07911329774651188, 0.991916986740037, 0.2813827476951407, -0.04853407905200813, -0.6005046367686679, -0.14304013354765055, 0.34286787732081714, -0.37445535142004815, -0.4400279267600409, -0.33907321248114686, -0.37837303194360317, 0.945141709094852, -0.683971963246832], [0.8540940740758476, 0.04861388945661349, -0.9467378842956955, 0.8365728984594432, -0.671038048562083, 0.25851231966164834, 0.9622742773321897, -0.1624026626986581, -0.9896560629018187, 0.8072858865671102, 0.9736878988942121, 0.17861290153450882, 0.10940544690711618, -0.8730713613228547, -0.6646436186777103, 0.23679883953292813, -0.4552336039826439, 0.6408472340913358, -0.6543284426483371, -0.30141157985381684, 0.44496382416060487, 0.17500744902661003, -0.32023394897066493, -0.0022167235368273364, -0.381770834023895, -0.28775636020658224, 0.3675656809092278, -0.34447310875318604, 0.07300873631407545, -0.37317126347410223], [0.5391780685040928, 0.02367004219503155, 0.13863564506197767, -0.04530548981712346, 0.5656804593949312, 0.44250184454097274, -0.36151010137978945, -0.6628246482899305, -0.1172038013204948, 0.7237079073843, -0.8376957486882841, 0.871765853256397, -0.28838296148084797, 0.27741791906661595, 0.5583524261505393, 0.18503979073451826, 0.757222149588137, -0.9262281598706767, -0.6096037363306197, -0.18917605827101602, -0.1658557691342144, -0.10215967708145857, -0.7025320926885859, -0.024967166137099595, 0.8703418196443338, -0.6960851941539934, -0.633930594488638, -0.686724307188529, -0.7910965683428357, -0.8887087210359776], [0.9826252270056228, 0.40973357525194265, 0.5565266781591525, 0.6927467781725694, -0.8644455733310281, -0.8626144758512653, 0.6452054904688331, 0.9377428552800928, -0.8268352150728222, 0.7652172017434902, 0.5795276366570672, 0.5060762913001795, 0.37824547793244845, -0.3560154763982779, 0.05533563067178626, 0.12264136690894478, 0.8512661591913149, -0.641903435163274, 0.5585270479669164, -0.7403182557023502, -0.2582571909751761, 0.35748713180284786, -0.18857210682082926, 0.7721276445180794, -0.05374254228525355, -0.8501368202276283, -0.49378756966072723, 0.4493239143938239, 0.7153738694310456, -0.21130702628943188], [0.5681618850318559, 0.11799381548531862, 0.2685162487814896, 0.7307796328312903, -0.864167663296346, 0.6579880053501204, 0.7767455537777987, 0.9177711486338844, 0.08683469970661939, 0.03139375295865032, 0.25041538750477943, -0.9359558980973712, 0.8888963622593944, 0.28906388709363173, -0.7908913007127956, -0.3865314011912966, -0.5175825060912029, 0.8157868742279841, 0.31443947376953685, -0.7308420329280938, 0.2604846470384399, 0.10741707309008408, 0.7078309292452174, 0.5580511509992456, -0.8108251643585942, 0.8925156100829921, 0.17481034448447796, -0.5700146305402753, -0.568805108683963, -0.9078771571749267], [0.6081747675829952, -0.7700607316764247, 0.39734904277630223, 0.8270959443978456, -0.40337570923748456, 0.18757187183462687, 0.5266801888683978, 0.9084090625572838, 0.1205113065098058, -0.49455829859582434, 0.26242478410855097, -0.9219005436971155, -0.9551255115045725, 0.495899005247477, 0.5609575168335097, -0.6630106285450961, 0.5896689750752395, 0.659971371452942, 0.20055286772248015, 0.26817567517585683, 0.8607677309697734, 0.5864095513290775, 0.39982592268179395, -0.8901015808217161, 0.4638905416434107, -0.2781527894057818, 0.7074674894562092, -0.5907627538687354, -0.3602813471960278, 0.22602081495466209], [-0.6592014750337383, 0.14984012978198957, -0.1554145963807878, 0.8639803161217601, 0.9735709650845186, -0.8424151206981372, 0.3111870126407652, 0.960161521752031, -0.6462387108255427, -0.7121819853071758, -0.37717077910961283, 0.4803263686170032, -0.16703526360721654, -0.46350620057514713, 0.0009271914037238815, -0.5233656201445529, 0.3372666567211897, -0.9994372244106846, 0.8529405895737419, 0.31384540519055726, 0.31050363357476596, -0.8424808509876989, 0.9421457003902372, 0.8098707330552466, -0.10746487787330938, -0.9180363148669084, 0.4313386059045914, -0.18757785134219707, -0.26593384174646095, -0.35384538265872245], [0.3824054980394753, -0.5304276002750439, -0.47410931986790983, -0.7086129479942089, 0.9883940326431866, -0.5231574029585295, -0.42743357580303853, 0.29242391912769383, 0.5570403816946901, 0.3399272990989215, -0.3720050721675219, 0.04547160034793474, -0.7495636610751786, 0.6267846571014775, 0.8932647046045683, 0.7524585183008636, 0.6378543885435521, -0.9822537078353901, 0.12216386639545074, -0.8265555822818544, -0.5279783265028846, -0.10576510302025266, -0.9642396781375027, -0.679187088516094, 0.47507173093856214, -0.7761749453657296, 0.6634812246739148, 0.8625978325906483, 0.6759897643362995, 0.6155072891021787], [0.9845754882777917, 0.036695459737910996, -0.17453971350983322, -0.4715856513583987, 0.16472829853294324, 0.12835025628512287, 0.34011427648304116, 0.6894300295534845, 0.20749024079465372, 0.3385576593132551, -0.4954544848754281, -0.20308048893486208, 0.38721011018193185, -0.27304930156410445, 0.830900268203846, 0.4861611154365386, 0.9737832836455587, -0.979383455749931, -0.765953129349398, -0.8860482583664704, -0.14449188300301463, 0.020705145708449946, 0.5210278914524638, 0.40005367370092326, -0.2819784631107438, -0.49664184468628725, -0.03231743704030676, 0.7405601223141527, -0.8871420203585085, -0.37217576227560456]]
        actualNewDifferentialErrorWeightsBiases, actualOldWeights = layer.passBackward(actualInput,actualOutput,expectedOutput=None,differentialErrorWeightsBiasInput=differentialErrorWeightsBiasInput,previousLayerWeights=previousLayerWeights)
        actualNewDifferentialErrorWeightsBiases = [[float(__) for __ in _] for _ in actualNewDifferentialErrorWeightsBiases]
        actualOldWeights = [[float(__) for __ in _] for _ in actualOldWeights]
        self.assertListEqual(expectedNewDifferentialErrorWeightsBiases, actualNewDifferentialErrorWeightsBiases, "ERROR : pass backward output actualNewDifferentialErrorWeightsBiases does not match")
        self.assertListEqual(expectedOldWeights, actualOldWeights, "ERROR : pass backward output actualOldWeights does not match")
    def testPassForward(self):
        layer = Layer()
        layer.weights = [[0.9501145370986877, 0.8463510649455349, -0.3681313899016718, 0.058997409044068555, 0.3169589613783439, -0.6950787682551808, -0.9816039340357129, -0.4933675114099293, -0.23599396384562926, 0.03793799070440219, -0.650855668346051, 0.23344351740858468, -0.1160311308407665, -0.056858104667780185, 0.3688140575913514], [0.37194646103100204, 0.2803340423479782, -0.43553674964483563, -0.1711258474225021, 0.495410916385576, -0.6892585451008046, -0.5026289381678785, -0.6165833168737461, -0.4162195751404222, 0.8836972189502543, -0.8861994790405473, 0.354860995123017, -0.25803158763437495, 0.7439499370543912, 0.5061052685036989], [-0.5043864281166084, -0.8579802970291293, -0.20562932659787486, 0.9014293497517005, -0.6626976356831853, 0.07280362175303859, -0.4202576119852054, 0.3260395620795958, 0.11681784873297209, -0.6831874725316317, -0.9154619072770303, 0.13575355768445468, 0.6615899612391261, 0.3545423424856722, -0.8954600115104003], [0.24429945457788604, 0.43529304853225115, -0.14369120498706414, 0.809554027789872, -0.7732672179729312, 0.7421962092306235, 0.522332297428954, 0.6712803887244081, -0.6625274198392389, -0.8557847881458093, 0.06079198550545172, 0.478852440847057, -0.6306529901631658, -0.4942965435211604, 0.6294687741093321], [0.9619539492223074, -0.6605034435391223, 0.9793775404758167, 0.3278265413473583, -0.6625547082467236, 0.2030278584851218, -0.3997185663240118, 0.4696474894667808, 0.9326567154157609, -0.8373683982614087, -0.1600848151529492, -0.519908598178503, -0.09051994007220236, -0.719581029925121, -0.5133892206809503], [-0.3252671488336895, -0.19940637245952553, -0.9372934200644923, -0.2529787242350105, -0.07195948067525453, -0.3993259022890962, -0.14379506679368417, -0.017210295411622646, 0.48346618517649265, -0.27170782766582086, 0.5372797878259933, -0.726874082943007, -0.2787183918641452, 0.7160480250721425, -0.9826963308448985], [0.7291030601306724, 0.04579440755400144, -0.43795337862062356, 0.24329780750791297, -0.18072239378006508, 0.23598241590880054, -0.013481610941232458, 0.6495223027139962, 0.037035422003634175, -0.12028327237007669, -0.09609517577278529, -0.43493880323401773, -0.4275586744436947, -0.010250839772263168, -0.03610420964799118], [0.4537645107083029, -0.8815047374076858, 0.41022001711969186, 0.22538760921735992, 0.06923393299713382, 0.16767484385921713, 0.05557058179905905, 0.6193267189008527, 0.06913040804392162, 0.8451569196373736, -0.6693949030030469, -0.043176222315740656, -0.3751414294422626, -0.33265604296889995, -0.4183188275621913], [0.11902418531477994, 0.08262107544865716, -0.4287375509082166, -0.7056486460568128, 0.6133779215898387, -0.5800541935340146, 0.6936458970170496, 0.5679015285831305, 0.41630622766665726, 0.6371316884489392, -0.8032174174924984, -0.3609945166816822, 0.38593401452681414, 0.04647411508553368, -0.6692563348908098], [0.4498323937759627, -0.7042973755637086, -0.10753223348545445, -0.06689128352481033, -0.2143499187371945, -0.5793822018472581, -0.0007812058314508839, -0.7678797123219865, 0.18913386988789674, -0.008508885090325007, -0.7152534601353253, -0.5679725333207376, 0.2698138436301448, -0.038746679437871655, 0.2654088962534709]]
        layer.biases = [-0.029661688088499203, -0.03858990395724638, 0.07386770800504623, -0.06737596775080462, -0.03531732897983656, -0.04454614793297623, -0.07190280478679907, -0.04773443293900871, -0.07331933775522477, -0.017770209769350877]
        input = (0.9639266885509782, 0.18400198863331352, 0.770259705851553, 0.5003590632635432, 0.5632349708154528, 0.44736540532446883, 0.984191703451851, 0.1211439027246642, 0.4033556118525067, 0.035945113395511756, 0.302738317284066, 0.43388641326249994, 0.6264536270087788, 0.8243373042835451, 0.7540442045006254)
        expectedOutput = [0.40096465179303503, 0.48363928578957455, 0.23929928854541319, 0.6535710917372655, 0.5262265260573831, 0.1302317796023787, 0.4955529348546947, 0.47805360002412367, 0.4445322283660338, 0.4125232068339199]
        expectedweightsBiasInput = [-0.40144733512690917, -0.06546622823610604, -1.1565249754214928, 0.6347736866589015, 0.1050024735466226, -1.898910979859579, -0.017788729653552174, -0.08784204042532968, -0.22278803344999748, -0.3535442810606441]
        actualOutput, actualWeightsBiasInput = layer.passForward(input)
        actualOutput = [float(_) for _ in actualOutput]
        actualWeightsBiasInput = [float(_) for _ in actualWeightsBiasInput]
        self.assertListEqual(expectedOutput, actualOutput, "ERROR : pass forward output does not match")
        self.assertListEqual(expectedweightsBiasInput, actualWeightsBiasInput, "ERROR : pass forward weightsBiasInput does not match")
        pass
    pass
    # test constructor
    @staticmethod
    def getRandomPerceptron():
        # randomize layers numbers, dimensions & comments
        layersNumber = randint(2,12)
        dimensions = [randint(2,100) for _ in range(layersNumber)]
        comments = "".join([choice(ascii_letters) for _ in range(15)])
        # construct perceptron
        perceptron = Perceptron.constructRandomFromDimensions(dimensions,comments)
        # return
        return perceptron, layersNumber, dimensions, comments
    def testDefaultConstructor(self):
        # random perceptron
        perceptron, layersNumber, dimensions, comments = testPerceptron.getRandomPerceptron()
        # check layers dimensions
        differentWeights = False
        perceptronLayersDimension = layersNumber-1
        self.assertEqual(perceptronLayersDimension, len(perceptron.layers), "ERROR : perceptron layers number")
        self.assertEqual(dimensions[0], len(perceptron.layers[0].weights[0]), "ERROR : first layer column dimension")
        self.assertEqual(dimensions[-1], len(perceptron.layers[-1].weights), "ERROR : last layer row dimension")
        for layerIndex in range(perceptronLayersDimension):
            firstWeight = perceptron.layers[layerIndex].weights[0][0]
            if layerIndex < perceptronLayersDimension-1 :
                nextLayerIndex = layerIndex+1
                self.assertEqual(dimensions[nextLayerIndex], len(perceptron.layers[nextLayerIndex].weights[0]), "ERROR : next layer column dimensions")
                self.assertEqual(len(perceptron.layers[layerIndex].weights), len(perceptron.layers[nextLayerIndex].weights[0]), "ERROR : layers row/column dimensions")
            rowsNumber = len(perceptron.layers[layerIndex].weights)
            self.assertEqual(perceptron.layers[layerIndex].biases, [0]*rowsNumber, "ERROR : bias != 0")
            for row in range(rowsNumber):
                for column in range(len(perceptron.layers[layerIndex].weights[0])):
                    currentWeight = perceptron.layers[layerIndex].weights[row][column]
                    self.assertGreaterEqual(currentWeight, -1, "ERROR : weight < -1")
                    self.assertLessEqual(currentWeight, 1, "ERROR : weight > 1")
                    if not differentWeights : differentWeights = firstWeight != currentWeight
                    pass
                pass
            self.assertTrue(differentWeights, "ERROR : all weights are the same")
            pass
        # check comments
        self.assertEqual(comments, perceptron.comments, "ERROR : perceptron comment")
    # test constructor
    def testPerceptronConstructorFromAttributes(self):
        # random perceptron
        initialPerceptron, _, _, _ = testPerceptron.getRandomPerceptron()
        initialPerceptron.id = randint(0, 1000)
        # construct from attributes
        constructedPerceptron = Perceptron.constructFromAttributes(initialPerceptron.id,initialPerceptron.layers,initialPerceptron.comments)
        # check construction
        self.assertTrue(initialPerceptron==constructedPerceptron, "ERROR : perceptron not consistent with attributs")
        pass
    def testLayerConstructorFromAttributes(self):
        # random layer
        previousDimension = randint(2,12)
        currentDimension = randint(2,12)
        initialLayer=Layer.constructRandomFromDimensions(previousDimension, currentDimension)
        # construct from attributes
        constructedLayer = Layer.constructFromAttributes(initialLayer.weights,initialLayer.biases)
        # check construction
        self.assertTrue(initialLayer==constructedLayer, "ERROR : layer not consistent with attributs")
        pass
    pass
pass
